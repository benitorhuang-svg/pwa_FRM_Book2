{
  "id": "b2_ch8",
  "title": "第8章：市場風險",
  "number": 8,
  "content": {
    "intro": {
      "title": "第 8 章：市場風險 - 重點詳解 (Detail)",
      "roadmap": {
        "guide": "市場風險是指金融機構由於市場價格（股價、利率、匯率、商品價格）的不利變動而遭受損失的風險。本章聚焦於風險價值（Value at Risk, VaR）的理論與實務，介紹了金融機構如何量化「在特定置信水平下可能的極大損失」。",
        "objectives": "*   理解 VaR 的定義：$\\text{Prob}(\\Delta P < -\\text{VaR}) = 1 - c$。\n*   掌握 VaR 計算的三大主流方法及其優缺點與適用場景。\n*   理解為何 ES (Expected Shortfall)比 VaR 更具備「凝聚性」（Coherence），特別是在尾部風險度量上。",
        "topics": "*   8.1 市場風險 (Market Risk) 及其分類\n*   8.2 市場風險度量：從標準差到 VaR\n*   8.3 風險價值 (VaR) 與預期損失 (Expected Shortfall)\n*   8.4 參數法 (Parametric Method) 計算 VaR\n*   8.5 歷史法 (Historical Simulation) 計算 VaR\n*   8.6 蒙地卡羅法 (Monte Carlo Method) 計算 VaR"
      },
      "value": {
        "practical": "*   **實務場景**：每日計算證券持倉的 VaR 值，並與預先設定的風險限額（Risk Limits）進行對比。\n*   **考試重點**：理解歷史模擬法不需要分佈假設，而參數法則強烈依賴常態性假設。",
        "theory": "VaR 是巴塞爾協定的核心。ES (Expected Shortfall) 解決了 VaR 無法描述「尾部損失具體是多少」的缺點。三種方法各具特色：參數法快、歷史法真、蒙地卡羅法靈活。",
        "further_reading": "*   Jorion (2006) Value at Risk."
      },
      "implementation": {
        "python": "*   **報告生成**：使用 `prettytable` 套件建立專業的風險報告。\n*   **滾動計算**：實作動態波動率估算與隨時變動的 VaR 視覺化。\n*   **隨機建模**：利用蒙地卡羅模擬 (`np.random.normal`) 計算複雜資產組合的 VaR。",
        "logic": "*   分位數分析：透過 `np.percentile` 提取風險閾值。\n*   動態 VaR：分析風險如何隨市場波動自調整。",
        "scenarios": "| 腳本名稱 | 核心使命 |\n| :--- | :--- |\n| **B2_Ch8_1.py** | 實作基礎 VaR 計算，演示使用 `PrettyTable` 進行風險報告格式化。 |\n| **B2_Ch8_2.py** | 演示多種置信水平（95%, 99%）下的 VaR 計算與統計對比。 |\n| **B2_Ch8_3.py** | **[進階]** 實作滾動窗口波動率計算與 VaR 信賴區間的動態視覺化。 |\n| **B2_Ch8_4.py** | 分析收益率分佈特徵，演示 VaR 計算中的統計推斷與分位數分析。 |\n| **B2_Ch8_5.py** | **[核心]** 利用蒙地卡羅模擬生成隨機路徑，計算非線性資產組合的 VaR。 |"
      }
    },
    "body": {
      "8.1": "### 8.1 市場風險 (Market Risk) 及其分類：波動中的損失預警\n市場風險是金融機構最核心的風險來源，指的是由於市場因子（利率、匯率、股價及商品價格）的不利變動而導致資產負債表出現損失的機率。資深風險經理不僅要識別風險，更要透過建立「風險因子地圖」來理解不同資產類別間的非線性聯動。\n\n#### 專家決策矩陣：市場風險的四大支柱\n資深分析師必須將宏觀變動轉化為微觀的持倉衝擊：\n\n| 風險維度 | 驅動因子 | 典型風險合約 |\n| :--- | :--- | :--- |\n| **權益風險** | 股票價格、股指波動、股息率 | 個股、ETF、股指期貨、股本互換 |\n| **利率風險** | 收益率曲線平移、扭曲與凸性 | 國債、利率互換 (IRS)、FRN |\n| **匯率風險** | 兩國匯率波動、利率平價偏離 | 貨幣對、外匯遠期、交叉匯率期權 |\n| **商品風險** | 原油、黃金等大宗商品價格 | 商品期貨、結構性商品票據 |\n\n#### 技術核心：風險因子的傳導機制\n市場風險的度量核心在於「映射」(Mapping)。資深從業人員透過將複雜的證券（如含權債券）映射到基礎風險因子（如零息利率）上，實現了全組合風險的橫向對比與彙總。\n\n> [!IMPORTANT]\n> 在生產端生成的風險報告中（見 `B2_Ch8_1.py`），我們使用 `PrettyTable` 結構化展現各維度風險。資深開發者應確保報告包含「極大回撤」與「當前敞口」的對比，這能直觀預警是否觸及了內部紅線或監管限制。\n\n#### 8.1 資深從業人員行動清單 (Action Items)\n執行市場風險分類審核前，必須：\n- **因子覆蓋範圍校準**：確保風險模型已納入所有對投資組合具有實質影響的二階因子（如波動率偏斜）。\n- **映射邏輯驗證**：審核複雜產品的分解邏輯，確保其 Delta/Gamma 等希臘字母已正確對應至標的資產池。\n- **監管指標核對**：比對巴塞爾協議 (Basel III) 的基本要求，確保分類標準符合合規披露要求。",
      "8.2": "### 8.2 市場風險度量：從標準差到 VaR 的風險躍演\n傳統的風險度量多依賴資產收益率的標準差 (Volatility)，然而標準差僅描述了平均波動幅度，無法揭示損失的極端邊界。**風險價值 (Value at Risk, VaR)** 的出現，為全球金融體系提供了一種標準化的語言：在特定置信水平與持有期內，資產可能遭遇的最大損失額。\n\n#### 專家定義：VaR 的數學與機率特徵\n給定置信水平 $c$（如 99%）與持有期 $T$，VaR 定義為損失 $\\Delta P$ 超過該值的機率為 $1-c$：\n\n$$\n  \\text{Prob}(\\Delta P < -\\text{VaR}) = 1 - c\n$$\n\n#### 專家決策矩陣：常用置信水平與時間尺度的決策\n資深分析師根據業務與監管需求選取特定參數：\n\n| 參數類型 | 數值設定 | 適用場景與含義 |\n| :--- | :--- | :--- |\n| **置信水平 (c)** | **95%** | 內部風險日常控管，更能反映「頻發」的小規模損失 |\n| **置信水平 (c)** | **99%** | **監管規法（巴塞爾）標準**：衡量銀行資本充足率的核心指標 |\n| **持有期 (T)** | **1 天** | 適用於流動性強的證券頭寸（如貨幣市場、匯市） |\n| **持有期 (T)** | **10 天** | 監管規定的最低風險資本（Market Risk Capital）計算基期 |\n\n> [!IMPORTANT]\n> 在 VaR 計算中（見 `B2_Ch8_2.py`），資深從業人員必須識別「平方根時間法則」(Square Root Day Rule) 的局限性。當市場存在厚尾或自相關時，簡單地將 1 天 VaR 乘以 $\\sqrt{10}$ 獲取 10 天 VaR 會導致風險嚴重的低估。\n\n#### 8.2 資深從業人員行動清單 (Action Items)\n設定 VaR 監控指標前，必須確認：\n- **分佈正態性檢定**：確認標的資產收益率是否具備「肥尾」特徵，若有，則嚴禁僅使用基於正態分佈的 VaR。\n- **數據窗口選取**：明確回報率計算的取樣範圍（如過去 252 或 500 個交易日），並對近期波動進行加權處理 (EWMA)。\n- **損益幣種統一**：確保跨市場組合的損益已換算為單一本幣 (Base Currency)，消除匯率造成的虛假抵銷效應。",
      "8.3": "### 8.3 預期損失 (Expected Shortfall)：超越臨界點的真實恐慌\n雖然 VaR 指明了最大損失的門檻，但它對「超過門檻後會虧多少」完全失靈。為了修正這一缺陷，**預期損失 (Expected Shortfall, ES)** 或稱條件風險價值 (CVaR) 被引入。ES 衡量的是損失超過 VaR 閾值後的平均損失水平。資深分析師深知，在尾部事件觸發時，ES 才是決定公司能否生存的關鍵。\n\n#### 技術核心：ES 的一致性（Coherence）優勢\n根據 Artzner et al. (1999) 的理論，ES 滿足「次可加性」(Sub-additivity)，這意味著多元化投資一定會降低 ES。而 VaR 在極端分佈下可能違反此原則。\n\n$$\n  \\text{ES}_c = E[L \\mid L > \\text{VaR}_c]\n$$\n\n#### 專家決策矩陣：VaR vs. ES 的風險博弈\n在不同的管理層級中，這兩個指標具備不同的決策權重：\n\n| 指標 | 優點 | 致命弱點 |\n| :--- | :--- | :--- |\n| **VaR** | 簡單、易於溝通、是全球監管指標 | **尾部盲點**：不關心損失分佈的極端尾部 |\n| **ES** | **捕捉極端風險**、符合次可加性（凝聚性） | **回測困難**：對超過閾值的期望值檢驗需要巨量數據 |\n\n> [!IMPORTANT]\n> 在滾動窗口計算中（見 `B2_Ch8_3.py`），資深開發者會觀察 VaR 與 ES 的間距。當間距突然擴大時，代表市場分佈出現了劇烈的「肥尾」跡象。此時應立即啟動二級警報，而非等待價格觸碰 VaR 閾值。\n\n#### 8.3 資深從業人員行動清單 (Action Items)\n執行尾部風險評估時，必須落實：\n- **ES 計算標準化**：選取與 VaR 一致的參數（如 97.5% ES 對標以前的 99% VaR，依據 FRTB 監管新制）。\n- **尾部肥大係數審核**：計算 Kurtosis（峰度），若峰度 $> 3$，ES 相比 VaR 的溢價將顯著提升。\n- **策略限制管理**：不僅設定 VaR 限額，更應針對高槓桿頭寸設定 ES 止損紅線，防範「低機率高破壞」的系統性風險。",
      "8.4": "### 8.4 參數法 (Parametric Method)：基於正態假設的極速計算\n參數法（又稱變異數-共變異數法）假設資產收益率服從特定分佈（通常為正態分佈）。其核心在於透過估算均值 $\\mu$ 與標準差 $\\sigma$，利用正態分佈的分位數快速獲取風險數值。它是大規模投資組合風險彙總中最直接、計算資源消耗最低的方案。\n\n#### 技術核心：線性組合與分位數函數\n在正態分佈假設下，1 天的 VaR 計算公式如下：\n\n$$\n  \\text{VaR}_c = -\\text{Value} \\cdot (\\mu - z_{1-c} \\sigma)\n$$\n\n其中 $z$ 是對應置信水平的分位數（例如 95% 時 $z \\approx 1.645$, 99% 時 $z \\approx 2.326$）。\n\n#### 專家決策矩陣：參數法的適用與風險邊界\n資深計量師必須識別何時該放棄此方法：\n\n| 市場情境 | 表現評価 | 決策建議 |\n| :--- | :--- | :--- |\n| **線性資產（股票、外幣、期貨）** | 優異 | 只要數據平穩且無厚尾，此法精確度可接受 |\n| **含權資產（期權、結構債）** | **失效** | 忽略了 Gamma 等非線性風險，會嚴重偏差 |\n| **極端動盪市場 (Crisis)** | **失效** | 實際損失往往是正態預測的數倍（黑色星期一現象） |\n\n> [!IMPORTANT]\n> 在生產端演算法中（見 `B2_Ch8_1.py`），我們利用 `scipy.stats.norm.ppf` 獲取分位數。資深開發者在使用此公式時，必須定期進行正態性檢定（如 Shapiro-Wilk Test）。若檢定未通過，應考慮升級至「t-分佈」參數法以捕捉肥尾。\n\n#### 8.4 資深從業人員行動清單 (Action Items)\n執行參數法計算前，必須確認：\n- **協方差矩陣穩定性**：針對多資產組合，確保各資產間的相關係數不隨市場波動而發生「相關性崩潰」(Correlation Breakdown)。\n- **波動率估計模型選型**：決定使用簡單移動平均 (SMA) 還是能反映波動聚集性的 EWMA 或 GARCH。\n- **非線性偏移校正**：若對含權組合使用此法，必須增加修正項（如 Delta-Gamma 近似），否則應被視為瑕疵模型。",
      "8.5": "### 8.5 歷史模擬法 (Historical Simulation)：讓真實歷史來說話\n歷史模擬法不依賴於任何特定的統計分佈假設。它直接將過去 $N$ 天的實際收益率變動「重播」於當前持倉，透過分位數排序選取風險值。資深分析師青睞此法，因為它能天然捕捉金融數據中的厚尾與相關性，避開了參數法過於理想化的假設陷阱。\n\n#### 技術核心：非參數分位數提取\n收集過去 $N$ 天的收益率序列 $R = \\{r_1, r_2, ..., r_n\\}$，將其與當前資產價值 $V$ 相乘得到模擬損益，隨後提取指定百分位數：\n\n$$\n  \\text{VaR}_c = -\\text{Percentile}(\\text{Profit\\&Loss}, 1-c)\n$$\n\n#### 專家決策矩陣：歷史模擬法的優化與挑戰\n資深從業人員必須妥善處理數據長度的權衡：\n\n| 數據長度 ($N$) | 優點 | 缺陷 |\n| :--- | :--- | :--- |\n| **短窗口 (252 天)** | 反應市場最新趨勢 | 樣本量不足，VaR 估計值不穩定（Sampling Error） |\n| **長窗口 (500-1000 天)** | **統計穩健**：包含更多歷史極端事件 | 可能過度依賴已過時的低波動環境，導致反應遲鈍 |\n| **BRW 加權法** | 調和了兩者，對近期賦予更高權重 | **資深首選**：解決了歷史法「幽靈效應」問題 |\n\n> [!IMPORTANT]\n> 在 Python 實作中（見 `B2_Ch8_4.py`），資深開發者會使用 `np.percentile` 搭配 `interpolation='linear'`。必須警惕「幽靈效應」(Ghosting Effect)：當一年前的大波動突然退出計算窗口時，VaR 會在沒有任何新市場變動的情況下突降。此時應標註為模型技術變動而非風險降低。\n\n#### 8.5 資深從業人員行動清單 (Action Items)\n執行歷史模擬時，必須落實：\n- **數據一致性審計**：確保所有歷史變動序列具有可比性，若發生基礎設施變動（如拆股、大規模派息），需回溯調整。反映。\n- **收益率選型決策**：決定採用「絕對變動」還是「相對變動」，後者更適合價格水平波動巨大的資產。\n- **定期重播迴測**：利用當前持倉回測歷史上的「黑天鵝」交易日（如 2008 雷曼、2020 疫情熔斷），評估生存能力。",
      "8.6": "### 8.6 蒙地卡羅法 (Monte Carlo Method)：針對複雜衍生品的終極模擬\n蒙地卡羅模擬法是風險管理中最靈活但也最耗能的工具。它透過生成數萬條符合特定隨機過程（如 GBM）的路徑，模擬投資組合在未來的價值分佈。對於包含路障、提前行權或路徑依賴等複雜條款的衍生品，蒙地卡羅法是唯一能提供完整風險圖譜的解決方案。\n\n#### 技術核心：隨機路徑生成邏輯\n資深從業人員通常使用幾何布朗運動 (GBM) 作為股票風險的基石，其離散化路徑如下：\n\n$$\n  S_{t+\\Delta t} = S_t \\exp\\left( (\\mu - \\sigma^2/2)\\Delta t + \\sigma \\epsilon \\sqrt{\\Delta t} \\right)\n$$\n\n其中 $\\epsilon \\sim N(0, 1)$ 是每一路徑上的獨立隨機噪音。\n\n#### 專家決策矩陣：蒙地卡羅法的執行效率與精度\n資深計量師需在算力與誤差間尋求平衡：\n\n| 優化策略 | 原理 | 實務價值 |\n| :--- | :--- | :--- |\n| **對偶變量 (Antithetic)** | 使用 $\\epsilon$ 與 $-\\epsilon$ 同時路徑模擬 | 顯著降低隨機噪音帶來的估值方差 |\n| **控製變量 (Control)** | 利用已知解析解的類似資產進行偏差修正 | 大幅提升收斂速度 |\n| **平行計算 (GPU/Multi-threading)** | 同時計算數萬條路徑 | **資深開發標準**：將小時級別的模擬縮短至秒級 |\n\n> [!IMPORTANT]\n> 在生產端建構模擬系統時（見 `B2_Ch8_5.py`），資深開發者會使用 `np.random.seed` 以確保結果的可重複性。在使用蒙地卡羅 VaR 時，必須監控「收斂標準差」(Standard Error of Mean)，若 $N=10,000$ 的結果波動太大，則必須增加路徑數至 $100,000$ 或引入方差縮減技術。\n\n#### 8.6 資深從業人員行動清單 (Action Items)\n執行蒙地卡羅模擬前，必須確認：\n- **模型風險識別**：確認選取的隨機過程（如 GBM, Jump-Diffusion）是否足以描述現實中資產的跳躍行為。\n- **相關性結構嵌入**：在多資產模擬中，利用 Cholesky 分解將資產間的相關係數矩陣嵌入隨機噪音池中。\n- **尾部穩定性測試**：針對 99% VaR，必須確保有足夠的「極端路徑」落下，且這些路徑的損益计算邏輯符合合規要求。\n\n#### 核心技術結論\n市場風險度量是金融韌性的「診斷書」。從參數法的快速概覽到蒙地卡羅法的精密解剖，資深從業人員必須具備在不同方法間靈活切換的能力，確保在任何市場週期下，機構對極端損失皆有明確的「數量化預案」。"
    },
    "examples": [
      {
        "id": "ex1",
        "title": "8.1 基礎 VaR 計算 (PrettyTable)",
        "filename": "B2_Ch8_1.py",
        "code": "# B2_Ch8_1.py\n\n###############\n# Prepared by Ran An, Wei Lu, and Feng Zhang\n# Editor-in-chief: Weisheng Jiang, and Sheng Tu\n# Book 2  |  Financial Risk Management with Python\n# Published and copyrighted by Tsinghua University Press\n# Beijing, China, 2021\n###############\n\nfrom prettytable import PrettyTable\n   \n# position R1\nx = PrettyTable([\"Payout\", \"Probability\"])\nx.add_row([-50, 0.02])\nx.add_row([0, 0.98])\nx.add_row(['97% VaR', 0])\nprint(x.get_string(title=\"Position R1\"))\n\n# position R2\nx = PrettyTable([\"Payout\", \"Probability\"])\nx.add_row([-50, 0.02])\nx.add_row([0, 0.98])\nx.add_row(['97% VaR', 0])\nprint(x.get_string(title=\"Position R2\"))"
      },
      {
        "id": "ex2",
        "title": "8.2 VaR 計算與統計對比",
        "filename": "B2_Ch8_2.py",
        "code": "# B2_Ch8_2.py\n\n###############\n# Prepared by Ran An, Wei Lu, and Feng Zhang\n# Editor-in-chief: Weisheng Jiang, and Sheng Tu\n# Book 2  |  Financial Risk Management with Python\n# Published and copyrighted by Tsinghua University Press\n# Beijing, China, 2021\n###############\n\nfrom prettytable import PrettyTable\n   \n# combination of R1 and R2\n# probability of 3 possible payouts\np1 = 0.02*0.02\np2 = 2*0.02*0.98\np3 = round(0.98*0.98, 4)\n\nx = PrettyTable([\"Payout\", \"Probability\"])\nx.add_row([-100, p1])\nx.add_row([-50, p2])\nx.add_row([0, p3])\nprint(x.get_string(title=\"Combination of positions R1 and R2\"))\nx.add_row(['97% VaR', 50])\n"
      },
      {
        "id": "ex3",
        "title": "8.3 滾動窗口波動率與動態 VaR",
        "filename": "B2_Ch8_3.py",
        "code": "# B2_Ch8_3.py\n\n###############\n# Prepared by Ran An, Wei Lu, and Feng Zhang\n# Editor-in-chief: Weisheng Jiang, and Sheng Tu\n# Book 2  |  Financial Risk Management with Python\n# Published and copyrighted by Tsinghua University Press\n# Beijing, China, 2021\n###############\n\n# B2_Ch8_3_A.py\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pandas_datareader\nimport scipy.stats as stats\nfrom mpl_toolkits import mplot3d\nfrom matplotlib import cm\n    \ntickers = ['GOOGL','FB','AAPL','NFLX','AMZN']\nticker_num = len(tickers)\nprice_data = []\nfor ticker in range(ticker_num):   \n    prices = pandas_datareader.DataReader(tickers[ticker], start='2015-11-30', end = '2020-11-30', data_source='yahoo')   \n    price_data.append(prices[['Adj Close']])\n    df_stocks = pd.concat(price_data, axis=1)\n    \n# stock log returns\nlogreturns = np.log(df_stocks/df_stocks.shift(1))[1:]  \nlogreturns.columns = tickers \nlogreturns.head() \n\n# B2_Ch8_3_B.py\n# plot log return distribution for GOOGL\nplt.style.use('ggplot')\nmu, std = stats.norm.fit(logreturns['GOOGL'])\nx = np.linspace(mu-5*std, mu+5*std, 500)\nlogreturns['GOOGL'].hist(bins=60, density=True, histtype=\"stepfilled\", alpha=0.5)\nx = np.linspace(mu - 3*std, mu+3*std, 500)\nplt.plot(x, stats.norm.pdf(x, mu, std))\nplt.title(\"Log return distribution for GOOGL\")\nplt.xlabel(\"Return\")\nplt.ylabel(\"Density\")\n\n# B2_Ch8_3_C.py\n# plot log return distribution\nrows = 2\ncols = 2\nfig, axs = plt.subplots(rows, cols, figsize=(12,6))\nticker_n = 1\nfor i in range(rows):\n    for j in range(cols):\n        mu, std = stats.norm.fit(logreturns[tickers[ticker_n]])\n        x = np.linspace(mu-5*std, mu+5*std, 500)\n        axs[i,j].hist(logreturns[tickers[ticker_n]], bins=60, density=True, histtype=\"stepfilled\", alpha=0.5)\n        axs[i,j].plot(x, stats.norm.pdf(x, mu, std))\n        axs[i,j].set_title(\"Log return distribution for \"+tickers[ticker_n])\n        axs[i,j].set_xlabel(\"Return\")\n        axs[i,j].set_ylabel(\"Density\")\n        ticker_n = ticker_n + 1\nplt.tight_layout()\n\n\n# B2_Ch8_3_D.py\n# covariance matrix\ncov_logreturns = logreturns.cov() \n# mean returns for each stock\nmean_logreturns = logreturns.mean() \n# weights for stocks in the portfolio\nstock_weight = np.array([0.2, 0.3, 0.1, 0.15, 0.25]) \n# mean returns and volitality for portfolio  \nportfolio_mean_log = mean_logreturns.dot(stock_weight) \nportfolio_vol_log = np.sqrt(np.dot(stock_weight.T, np.dot(cov_logreturns, stock_weight)))\nprint('The mean and volatility of the portfolio are {:.6f} and {:.6f}, respectively.'.format(portfolio_mean_log, portfolio_vol_log))\n\n\n# B2_Ch8_3_E.py\n# confidence level\nconfidence_level = 0.99\n# VaR calculation: initial investment value and holding period\ninitial_investment = 1000000\nn = 1\nVaR_norm = initial_investment*(portfolio_vol_log*abs(stats.norm.ppf(q=1-confidence_level))-portfolio_mean_log)*np.sqrt(n)\nVaR_lognorm = initial_investment*(1-np.exp(portfolio_mean_log-portfolio_vol_log*abs(stats.norm.ppf(q=1-confidence_level))))*np.sqrt(n)\nprint('The normal VaR and lognormal VaR of the portfolio in 1 day holding period are {:.0f} and {:.0f}, respectively.'.format(VaR_norm, VaR_lognorm))\n\n\n\n# B2_Ch8_3_F.py\n# confidence level list\nconfidence_level_list = np.arange(0.90, 0.99, 0.001)\n# initial investment value\ninitial_investment = 1000000\nn = 1\nVaR_norm_list = []\nVaR_lognorm_list = []\nfor confidence_level in confidence_level_list:\n    VaR_norm = initial_investment*(portfolio_vol_log*abs(stats.norm.ppf(q=1-confidence_level))-portfolio_mean_log)*np.sqrt(n)\n    VaR_norm_list.append(VaR_norm)\n    VaR_lognorm = initial_investment*(1-np.exp(portfolio_mean_log-portfolio_vol_log*abs(stats.norm.ppf(q=1-confidence_level))))*np.sqrt(n)\n    VaR_lognorm_list.append(VaR_lognorm)\nplt.plot(confidence_level_list, VaR_norm_list, label='Normal VaR')\nplt.plot(confidence_level_list, VaR_lognorm_list, label='Lognormal VaR')\nplt.legend()\nplt.xlabel('Confidence level')\nplt.ylabel('1-day VaR')\n\n\n\n# B2_Ch8_3_G.py\n# 3D display \nholding_period_list = np.arange(1,91,1)\nfig = plt.figure()\nax = plt.axes(projection='3d')\nxdata = confidence_level_list\nydata = holding_period_list\nx3d, y3d = np.meshgrid(xdata, ydata)\nz3d = initial_investment*(portfolio_vol_log*abs(stats.norm.ppf(q=1-x3d))-portfolio_mean_log)*np.sqrt(y3d)\nax.plot_wireframe(x3d, y3d, z3d, rstride=4, cstride=4, linewidth=1, color='black')\nax.plot_surface(x3d, y3d, z3d, rstride=4, cstride=4, alpha=0.4,cmap=plt.cm.summer)\nax.set_xlabel('\\nConfidence level')\nax.set_ylabel('\\nHolding period')\nax.set_zlabel('\\nVaR')"
      },
      {
        "id": "ex4",
        "title": "8.4 收益率分佈與 VaR 統計推斷",
        "filename": "B2_Ch8_4.py",
        "code": "# B2_Ch8_4.py\n\n###############\n# Prepared by Ran An, Wei Lu, and Feng Zhang\n# Editor-in-chief: Weisheng Jiang, and Sheng Tu\n# Book 2  |  Financial Risk Management with Python\n# Published and copyrighted by Tsinghua University Press\n# Beijing, China, 2021\n###############\n\n# B2_Ch8_4_A.py\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas_datareader\nimport scipy.stats as stats\nimport tabulate    \n \nprices = pandas_datareader.DataReader('AAPL', start='2015-11-30', end = '2020-11-30', data_source='yahoo')   \ndf_stocks = prices[['Adj Close']]\n    \n# stock returns\nreturns = np.log(df_stocks/df_stocks.shift(1))\nreturns = returns.dropna()\n\n\n\n# B2_Ch8_4_B.py\n# historical VaR\nreturns.sort_values('Adj Close', ascending=True, inplace=True)\nHistVaR_90 = returns.quantile(0.1, interpolation='lower')[0]\nHistVaR_95 = returns.quantile(0.05, interpolation='lower')[0]\nHistVaR_99 = returns.quantile(0.01, interpolation='lower')[0]\nprint(tabulate.tabulate([['90%', HistVaR_90], ['95%', HistVaR_95], ['99%', HistVaR_99]], headers=['Confidence level', 'Value at Risk']))\n\n\n# B2_Ch8_4_C.py\n# parameteric VaR\nmu = np.mean(returns['Adj Close'])\nstd = np.std(returns['Adj Close'])\nParaVaR_90 = stats.norm.ppf(0.1, mu, std)\nParaVaR_95 = stats.norm.ppf(0.05, mu, std)\nParaVaR_99 = stats.norm.ppf(0.01, mu, std)\nprint(tabulate.tabulate([['90%', ParaVaR_90], ['95%', ParaVaR_95], ['99%', ParaVaR_99]], headers=['Confidence level', 'Value at Risk']))\n\n\n\n# B2_Ch8_4_D.py\n# plot distribution \nplt.style.use('ggplot')\nfig, ax = plt.subplots(1,1, figsize=(12,6))\nx = np.linspace(mu-5*std, mu+5*std, 500)\nax.hist(returns['Adj Close'], bins=100, density=True, histtype=\"stepfilled\", alpha=0.5)\nax.axvline(HistVaR_95, ymin=0, ymax=0.2, color='g', ls=':', alpha=0.7, label='95% historical VaR')\nax.axvline(ParaVaR_95, ymin=0, ymax=0.2, color='b', ls=':', alpha=0.7, label='95% parametric VaR')\nax.plot(x, stats.norm.pdf(x, mu, std))\nax.legend()\nax.set_title(\"Return distribution\")\nax.set_xlabel(\"Return\")\nax.set_ylabel(\"Frequency\")\n"
      },
      {
        "id": "ex5",
        "title": "8.5 蒙地卡羅模擬 VaR 計算",
        "filename": "B2_Ch8_5.py",
        "code": "# B2_Ch8_5.py\n\n###############\n# Prepared by Ran An, Wei Lu, and Feng Zhang\n# Editor-in-chief: Weisheng Jiang, and Sheng Tu\n# Book 2  |  Financial Risk Management with Python\n# Published and copyrighted by Tsinghua University Press\n# Beijing, China, 2021\n###############\n\n# B2_Ch8_5_A.py\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pandas_datareader\nimport seaborn as sns\n\ntickers = ['GOOGL','FB','AAPL','NFLX','AMZN']\nticker_num = len(tickers)\nprice_data = []\nfor ticker in range(ticker_num):   \n    prices = pandas_datareader.DataReader(tickers[ticker], start='2015-11-30', end = '2020-11-30', data_source='yahoo')   \n    price_data.append(prices[['Adj Close']])\n    df_stocks = pd.concat(price_data, axis=1)\ndf_stocks.columns = tickers\n\n\n\n# B2_Ch8_5_B.py\n# cumulative returns\nstock_return = []\nfor i in range(ticker_num):  \n    return_tmp = np.log(df_stocks[[tickers[i]]]/df_stocks[[tickers[i]]].shift(1))[1:]  \n    return_tmp = (return_tmp+1).cumprod()\n    stock_return.append(return_tmp[[tickers[i]]])\n    return_all = pd.concat(stock_return,axis=1)\nreturn_all.head()\n\n\n\n# B2_Ch8_5_C.py\n# plot cumulative returns of all stocks\nplt.style.use('ggplot')\nfor i, col in enumerate(return_all.columns):\n    return_all[col].plot()\nplt.title('Cumulative returns')\nplt.xlabel('Date')\nplt.ylabel('Return')\nplt.xticks(rotation=30)\nplt.legend(return_all.columns)\n\n\n\n# B2_Ch8_5_D.py\n# lastest return and price values\nlatest_return = return_all.iloc[-1,:]\nlatest_price = df_stocks.iloc[-1,:]\nsigma = latest_return.std()\n\n# weights for stocks in the portfolio\nstock_weight = [0.2, 0.3, 0.1, 0.15, 0.25] \n\n# calculate expected return\nexpected_return = latest_return.dot(stock_weight)\nprint('The weighted expected portfolio return: %.2f' % expected_return)\n\n# calculate weighted price\nprice = latest_price.dot(stock_weight)\nprint('The weighted price of the portfolio: %.0f' % price)\n\n\n\n# B2_Ch8_5_E.py\n# monte carlo simulation\nMC_num = 500\n# --- added by limit_simulations.py: apply cap 1000\n__SIM_CAP = 1000\ntry:\n    if MC_num > __SIM_CAP:\n        print('Reducing MC_num from', MC_num, 'to', __SIM_CAP, 'to avoid heavy computation.')\n        MC_num = __SIM_CAP\nexcept Exception:\n    pass\n\nconfidence_level = 0.95\ntime_step = 1440\nfor i in range(MC_num):  \n  daily_returns = np.random.normal(expected_return/time_step, sigma/np.sqrt(time_step), time_step)\n  plt.plot(daily_returns)\nplt.axhline(np.percentile(daily_returns,(1.0-confidence_level)*100), color='r', linestyle='dashed')\nplt.axhline(np.percentile(daily_returns,confidence_level*100), color='g', linestyle='dashed')\nplt.axhline(np.mean(daily_returns), color='b', linestyle='solid')\nplt.xlabel('Time')\nplt.ylabel('Return')\n\n\n\n# B2_Ch8_5_F.py\n# plot return distribution\nsns.distplot(daily_returns, kde=True, color='lightblue')\nplt.axvline(np.percentile(daily_returns,(1.0-confidence_level)*100), color='red', linestyle='dashed', linewidth=2)\nplt.title(\"Return distribution\")\nplt.xlabel('Return')\nplt.ylabel('Frequency')\nplt.show()\n\n\n# B2_Ch8_5_G.py\ninitial_investment  = 1000000\nVaR = initial_investment*np.percentile(daily_returns,(1.0-confidence_level)*100)\nprint('The value at risk is %.0f' % VaR)"
      }
    ]
  }
}