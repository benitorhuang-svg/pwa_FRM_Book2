{
    "content": "### 4.6 嶺回歸 (Ridge Regression)：對抗多重共線性的 L2 懲罰\n在多因子模型中，因子之間的高度相關（多重共線性）會導致 OLS 估計出的係數方差極大，甚至導致模型崩潰。**嶺回歸**透過引入 L2 正則化項（係數平方和），強制縮減不穩定係數的數值，從而大幅提升模型在噪音環境下的穩健性。\n\n#### 專家定義：L2 懲罰函數\n嶺回歸透過懲罰係數的長度，在擬合度與係數規模間取得平衡：\n\n$$\n  \\min_{\\beta} \\left\\{ \\sum (y_i - \\mathbf{x}_i^T\\beta)^2 + \\alpha \\sum \\beta_j^2 \\right\\}\n$$\n\n#### 決策矩陣：懲罰參數 $\\alpha$ 的物理效應\n$\\alpha$ 的大小直接反映了我們對噪音的容忍度：\n\n| $\\alpha$ 級別 | 對係數的影響 | 偏差-方差 表現 |\n| :--- | :--- | :--- |\n| **$\\alpha \\to 0$** | 退化為標準 OLS 回歸 | 低偏差，高方差（易受噪音干擾） |\n| **$\\alpha$ 適中** | 係數向零縮減但不會變為零 | **最佳平衡點**：顯著提升預測精度 |\n| **$\\alpha \\to \\infty$** | 係數全部趨近於零 | 高偏差，低方差（模型失去解釋力） |\n\n> [!IMPORTANT]\n> 在生產端實作中（見 `B2_Ch4_9.py`），資深開發者會使用 `Ridge(normalize=True)` 或手動進行特徵縮放。這至關重要，因為 L2 懲罰對特徵的量綱非常敏感。若未進行正規化，量綱較大的因子將獲得不公平的懲罰優勢。\n\n#### 4.6 資深從業人員行動清單 (Action Items)\n執行 Ridge 回歸前，必須確認：\n- **係數跡線圖審核 (Trace Plots)**：繪製不同 $\\alpha$ 下的係數縮減曲線，觀察哪些因子最先被抑制。\n- **特徵量綱對白**：確保所有輸入因子（如利率、市盈率、回報率）均已轉換為標準正態分佈。\n- **交叉驗證選優**：利用 `RidgeCV` 自動搜索最優的 $\\alpha$ 參數，確保正則化強度具備數據支撐。"
}